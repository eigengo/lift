#!/bin/bash

IP=$(ip -o -4 addr list eth0 | perl -n -e 'if (m{inet\s([\d\.]+)\/\d+\s}xms) { print $1 }')
echo "MASTER_IP=$IP"

echo "preparing Spark"
# This is now unfortunately required, because shell needs to be executed in special scope to be able to update env vars
sed -i s/__SPARK_LOCAL_IP__/$IP/ /opt/spark-$SPARK_VERSION/conf/spark-env.sh
sed -i s/__MASTER__/$IP/ /opt/spark-$SPARK_VERSION/conf/spark-env.sh
. /opt/spark-1.2.0/conf/spark-env.sh

echo "starting Hadoop Namenode"
hadoop namenode -format > /dev/null 2>&1
service hadoop-namenode start > /dev/null 2>&1

echo "starting sshd"
/usr/sbin/sshd

sleep 5

echo "starting Spark Master"
${SPARK_HOME}/sbin/start-master.sh

while [ 1 ];
do
	tail -f /opt/spark-${SPARK_VERSION}/logs/*.out
        sleep 1
done